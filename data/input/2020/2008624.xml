<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: CNS Core: Small: A Principled Framework for Workload Distribution Techniques in Large-Scale Networks]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>333500.00</AwardTotalIntnAmount>
<AwardAmount>333500</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ann Von Lehmen</SignBlockName>
<PO_EMAI>avonlehm@nsf.gov</PO_EMAI>
<PO_PHON>7032924756</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Over the last decade, distributed computing and big data analytics have enabled unprecedented advancements in human life, including in medicine and health, education, business, and in stimulating new careers. And, it is fundamental to the computing industry, a significant economic engine for the US.  However, traditional approaches to distributed computing are developed as ad hoc solutions to individual applications. In the classical paradigm, the system designer specifies a simple model of the network, along with a few low-level design goals, such as high utilization and low job completion time, and then develops a fixed algorithm to distribute the computation across workers. Although this paradigm has  resulted in heuristics that work in practice, networks and applications continuously grow in complexity and heterogeneity, hence, the critical task of designing workload distribution algorithms that work well across a variety of conditions has become exceedingly difficult.  This proposal addresses that challenge by developing a general framework that can be used as applications and networks grow.  Ultimately, it will make distributed computing more explainable and better tailored to the needs of applications.&lt;br/&gt;&lt;br/&gt;Workload distribution has a long and rich history. However, the existing literature lacks design principles for reasoning about compute versus communication tradeoffs in large-scale networks. This proposal seeks to develop a principled framework for workload distribution techniques. It aims to provide the mathematical foundations behind function computation in distributed networks, where a function is an abstraction of a computation task, such as training a neural network, indexing the web, query processing, etc. Hence, the operator does not have to rely on heuristics or simplified models to decide on workload distribution. Instead, the proposed framework offers the trade-off space between cost and performance for the best use of available resources. This proposal aims to address the fundamental challenge of parallel function computation in distributed networks and how to enable rigorous mathematical analysis of deployed approaches by (i) developing a series of core principles for workload distribution systems through analyzing a variety of applications, including datacenter job scheduling, decentralized Stochastic Gradient Descent training, and erasure coding for inference jobs, and (ii) devising a novel scheduling framework for distributing computation tasks in distributed networks. The proposed framework leverages Littleâ€™s Law to minimize both communication and computation times when designing practical, robust, and high-performance workload distribution algorithms. The PIs will evaluate the proposed scheduler against state-of-the-art heuristic algorithms and pin-point the constraints and features that makes each heuristic a special use case of the generic framework.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/24/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2008624</AwardID>
<Investigator>
<FirstName>Muriel</FirstName>
<LastName>Medard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Muriel Medard</PI_FULL_NAME>
<EmailAddress><![CDATA[medard@mit.edu]]></EmailAddress>
<NSF_ID>000106371</NSF_ID>
<StartDate>08/24/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Manya</FirstName>
<LastName>Ghobadi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Manya Ghobadi</PI_FULL_NAME>
<EmailAddress><![CDATA[ghobadi@mit.edu]]></EmailAddress>
<NSF_ID>000791554</NSF_ID>
<StartDate>08/24/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>CAMBRIDGE</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>E2NYLCDML6V1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>E2NYLCDML6V1</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Instritute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~333500</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-071671b6-7fff-a7fe-45e4-cd7b899e80dc"> <p dir="ltr"><span>This project aimed to develop a principled framework for workload distribution techniques in data center networks. The work provided the mathematical foundations behind function computation in distributed networks, where a function is an abstraction of a computation task such as training a neural network, indexing the web, query processing, machine learning inference, etc.&nbsp;</span></p> <br /> <p dir="ltr"><span>Our objectives were two-fold. First, we planned to develop a series of core principles for workload distribution systems by analyzing various applications. These principles raise the level of abstraction in function computation theory to provide a framework for network operators to handle large-scale distributed computation tasks and choose the best acceptable performance constrained by their practical limitations. Second, we aimed to design and develop a distributed function scheduler that enables workloads to be specified using our abstractions by connecting the dots between function computation theory and practical workload distribution using a framework that can capture intermediate function computations and the communication overhead incurred between distributed workers. The contributions of this project are as follows.</span></p> <br /> <p dir="ltr"><span>First, we have developed Nona, a principled framework for distributing latency-sensitive jobs considering a cluster's compute and communication resources. In doing so, we developed a mathematical formulation to characterize the job completion time of a series of jobs distributed in a cluster with stochastic allocation strategies. From this formulation, we derived an optimization problem to find the optimal scheduling strategy. Nona&rsquo;s formulation used queueing-theoretic techniques to handle locality dependencies and to balance gains from parallelism with added network delay from congestion. Through careful propagation of probability distributions of different jobs' DAGs, we included stochastic dependency in our formulation. Further, we implemented a stochastic scheduler that uses the solution found by the optimization to perform placement decisions in real-time. Using real-world applications, we demonstrated that Nona improves the job completion time by an order of magnitude.</span></p> <br /> <p dir="ltr"><span>Second, we developed a distributed coded computation approach that allows for intermediate results to be released at an earlier stage than the final result. We introduced the novel concept of layered-resolution distributed coded computations such that lower resolutions of the final result are obtained from the collective results of the workers &ndash; at an earlier stage than the final result. This innovation makes it possible to have more effective deadline-based systems, since even if a computational job is terminated because of timing, an approximated version of the final result can be released. Based on our theoretical and empirical results, the average execution delay for the first resolution is notably smaller than for the final resolution.&nbsp;</span></p> <br /> <p dir="ltr"><span>Finally, we provided a flow-based coded caching framework for information-centric networks. We jointly optimized delivery rates, cross-coding across nodes/servers, and cache content allocation as a function of demand and the network&rsquo;s topology. Our model accounts for storage and transmission costs, demand asymmetry, and arbitrary multi-hop topologies, and relies on an ordered flow-based decoding schedule for the transmissions created by pairwise coded flows. Through extensive experiments over multiple topologies, we observed that our coded caching scheme reduced transmission costs over competitors by several orders of magnitude.</span></p> <br /> <p dir="ltr"><span>This project involved students ranging from undergraduate to graduate and postdoctoral levels, and exposed them to the multidisciplinary nature of research &ndash; from new queueing theory concepts to practical system architecture to application and experimental analysis of emerging workloads, enabled by the cross-stack approach of the CNS core project.</span></p> <br /></span></p> <p>&nbsp;</p><br> <p>  Last Modified: 01/04/2024<br> Modified by: Manya&nbsp;Ghobadi</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     This project aimed to develop a principled framework for workload distribution techniques in data center networks. The work provided the mathematical foundations behind function computation in distributed networks, where a function is an abstraction of a computation task such as training a neural network, indexing the web, query processing, machine learning inference, etc.     Our objectives were two-fold. First, we planned to develop a series of core principles for workload distribution systems by analyzing various applications. These principles raise the level of abstraction in function computation theory to provide a framework for network operators to handle large-scale distributed computation tasks and choose the best acceptable performance constrained by their practical limitations. Second, we aimed to design and develop a distributed function scheduler that enables workloads to be specified using our abstractions by connecting the dots between function computation theory and practical workload distribution using a framework that can capture intermediate function computations and the communication overhead incurred between distributed workers. The contributions of this project are as follows.     First, we have developed Nona, a principled framework for distributing latency-sensitive jobs considering a cluster's compute and communication resources. In doing so, we developed a mathematical formulation to characterize the job completion time of a series of jobs distributed in a cluster with stochastic allocation strategies. From this formulation, we derived an optimization problem to find the optimal scheduling strategy. Nonas formulation used queueing-theoretic techniques to handle locality dependencies and to balance gains from parallelism with added network delay from congestion. Through careful propagation of probability distributions of different jobs' DAGs, we included stochastic dependency in our formulation. Further, we implemented a stochastic scheduler that uses the solution found by the optimization to perform placement decisions in real-time. Using real-world applications, we demonstrated that Nona improves the job completion time by an order of magnitude.     Second, we developed a distributed coded computation approach that allows for intermediate results to be released at an earlier stage than the final result. We introduced the novel concept of layered-resolution distributed coded computations such that lower resolutions of the final result are obtained from the collective results of the workers  at an earlier stage than the final result. This innovation makes it possible to have more effective deadline-based systems, since even if a computational job is terminated because of timing, an approximated version of the final result can be released. Based on our theoretical and empirical results, the average execution delay for the first resolution is notably smaller than for the final resolution.     Finally, we provided a flow-based coded caching framework for information-centric networks. We jointly optimized delivery rates, cross-coding across nodes/servers, and cache content allocation as a function of demand and the networks topology. Our model accounts for storage and transmission costs, demand asymmetry, and arbitrary multi-hop topologies, and relies on an ordered flow-based decoding schedule for the transmissions created by pairwise coded flows. Through extensive experiments over multiple topologies, we observed that our coded caching scheme reduced transmission costs over competitors by several orders of magnitude.     This project involved students ranging from undergraduate to graduate and postdoctoral levels, and exposed them to the multidisciplinary nature of research  from new queueing theory concepts to practical system architecture to application and experimental analysis of emerging workloads, enabled by the cross-stack approach of the CNS core project.          Last Modified: 01/04/2024       Submitted by: ManyaGhobadi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
