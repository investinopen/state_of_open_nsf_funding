<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[MRI: Acquisition of High-Resolution Visualization Instrumentation to Support Collaborative, Interdisciplinary Research and Education]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>700000.00</AwardTotalIntnAmount>
<AwardAmount>700000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Deepankar Medhi</SignBlockName>
<PO_EMAI>dmedhi@nsf.gov</PO_EMAI>
<PO_PHON>7032922935</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Many complex problems cannot be addressed easily from the confines of individual disciplines because they require participation of many experts, each viewing the problem from their distinctive disciplinary perspective, and collaborations around shared data and knowledge. When interdisciplinary efforts involve massive amounts of different types of data, an invaluable approach to understand and analyze data is data visualization. The University of Texas at El Paso (UTEP) is acquiring high resolution, collaborative visualization instrumentation that will be housed in the newly constructed Interdisciplinary Research Building. The instrumentation will be a vital resource for UTEP’s established efforts in convergence research across science and engineering, e.g., through the NSF-funded CREST CyberShARE Center of Excellence and “Innovation through Institutional Integration” initiative. The research impacted by the acquired instrumentation will contribute to NSF’s Big 10 ideas in quantum computing, data revolution, convergence research, and INCLUDES. The expected outcome is increased research productivity resulting from insights afforded by the integration and manipulation of visualizations and examination of multiple perspectives. As such, the visualization instrumentation can contribute to advancement of our nation’s research capabilities in quantum computing and data analytics, as well as areas that are particularly relevant to border regions and in topical areas relevant to a region with a large under-served population (e.g., health and the environment, energy-water issues, and border security), and other areas such as cybersecurity and national defense. The instrumentation will also elevate the education and training of student researchers, in particular Latinx students who comprise 80% of UTEP’s student population, in areas of national need. Research students and those involved in training and associated coursework will graduate with domain expertise and knowledge in interpreting, managing, and visualizing data; experience in working in interdisciplinary teams; and an ability to use state-of-the-art visualization methods to advance discovery and generate new knowledge. PI Gates directs the NSF-funded Computing Alliance of Hispanic-Serving Institutions (CAHSI), the only INCLUDES Alliance focused on achieving parity in representation of Hispanics in computing. The Alliance will be instrumental in disseminating and involving other HSIs in education and research training efforts and facilitating partnerships to build research capacity. The visualization instrumentation also will be an important asset for the community, in particular those impacted by UTEP’s research, and for outreach efforts in exciting middle- and high-school students about studying STEM through engagement in visualization activities. &lt;br/&gt;&lt;br/&gt;The comprehensive research instrumentation is composed of integrated subsystems and a visualization wall composed of ultra-high-definition displays with an overall resolution of 124 megapixels that will enable viewing data at unprecedented levels of detail, and, as a result, will support analysis and discovery of new insights from various types of data (structured and unstructured, heterogeneous, and data with varying levels of quality). The windowing subsystem will allow researchers to input and analyze multiple datasets running simultaneously and provide the ability to compare datasets side-by-side in real time while a video conferencing subsystem will support collaboration with remote stakeholders, policymakers, other academics, and political leaders. The instrumentation will create the infrastructure that bridges data, computation, and visualization to grow collaborations across the university and externally. In particular, the infrastructure will provide researchers with the ability to  communicate disparate perspectives of information and knowledge; analyze large, integrated data sets; manipulate multi-dimensional models of phenomena (e.g., geological structures, molecules, and advanced material engineering); view simulation models that holistically combine both social and natural system components; view data and models that are useful and usable by stakeholders who may or may not be technically savvy; and support a purposeful participatory research process that facilitates collaborative reasoning among researchers and stakeholders, enabling convergence from different perspectives.  With UTEP’s expertise in machine learning, semantic technologies, visualization, team science, and data analytics, researchers will have access to technologies and the requisite training needed to accelerate advances in their research. Indeed, diverse team efforts result in greater scientific impact, innovation, productivity, and reach because of the ability of members to draw on each other’s expertise.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>09/03/2020</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2018999</AwardID>
<Investigator>
<FirstName>Chuan</FirstName>
<LastName>Xiao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chuan Xiao</PI_FULL_NAME>
<EmailAddress><![CDATA[cxiao@utep.edu]]></EmailAddress>
<NSF_ID>000523882</NSF_ID>
<StartDate>09/03/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Pederson</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark R Pederson</PI_FULL_NAME>
<EmailAddress><![CDATA[mrpederson@utep.edu]]></EmailAddress>
<NSF_ID>000736435</NSF_ID>
<StartDate>09/03/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alex</FirstName>
<LastName>Mayer</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alex S Mayer</PI_FULL_NAME>
<EmailAddress><![CDATA[amayer2@utep.edu]]></EmailAddress>
<NSF_ID>000262386</NSF_ID>
<StartDate>09/24/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ann</FirstName>
<LastName>Gates</LastName>
<PI_MID_INIT>Q</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ann Q Gates</PI_FULL_NAME>
<EmailAddress><![CDATA[agates@utep.edu]]></EmailAddress>
<NSF_ID>000374818</NSF_ID>
<StartDate>09/03/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>William</FirstName>
<LastName>Hargrove</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>William Hargrove</PI_FULL_NAME>
<EmailAddress><![CDATA[wlhargrove@utep.edu]]></EmailAddress>
<NSF_ID>000560896</NSF_ID>
<StartDate>09/03/2020</StartDate>
<EndDate>09/24/2020</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Natalia</FirstName>
<LastName>Villanueva Rosales</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Natalia Villanueva Rosales</PI_FULL_NAME>
<EmailAddress><![CDATA[nvillanuevarosales@utep.edu]]></EmailAddress>
<NSF_ID>000619167</NSF_ID>
<StartDate>09/03/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at El Paso</Name>
<CityName>EL PASO</CityName>
<ZipCode>799680001</ZipCode>
<PhoneNumber>9157475680</PhoneNumber>
<StreetAddress>500 W UNIVERSITY AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX16</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>C1DEGMMKC7W7</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT EL PASO</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>X5NKD2NFF2V3</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at El Paso]]></Name>
<CityName>El Paso</CityName>
<StateCode>TX</StateCode>
<ZipCode>799680001</ZipCode>
<StreetAddress><![CDATA[500 W. University]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX16</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~700000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The NSF Major Research Instrumentation (MRI) program provided funds to the University of Texas at El Paso (UTEP)&nbsp;to purchase high performance, fully immersive visualization instrumentation to advance interdisciplinary research and research training. The instrumentation is housed at the Visualization &amp; Interactive Collaboration (VizInC) Laboratory located in UTEP's new&nbsp;Interdisciplinary Research Building.&nbsp;&nbsp;Data and knowledge visualization are critical for analysis, understanding, discovery, and decision making. In addition, visualization instrumentation is critical to advance convergent research endeavors that have been a focus at UTEP over the last decade. The VizInC Lab is a resource for researchers, faculty, and professional staff who require an ultra-high resolution display surface geared for scientific exploratory research and collaboration.&nbsp; The lab is composed of two spaces, the visualization lab, and the interactive collaboration lab. The visualization lab can display high-resolution scientific data models and supports exploration of large complex data sets. The 3D projection system is available for faculty and researchers who require virtual reality capabilities for immersive visualization. This system is connected to a high-end rendering workstation. Paraview, the open-source data visualization tool, supports manipulation of complex data workflows, including those with different data formats and supports stereoscopic rendering for 3D visualizations and motion tracking. The multi-touch system is available for researchers who require interactive touch capabilities to facilitate exploration, understanding, and discovery of scientific models and datasets.&nbsp;&nbsp;</p> <p>Through training centered on how to use software and visualization instrumentation, students (undergraduate and graduate) build competencies that prepare them for a competitive workforce. Researchers and post-docs also receive guidance on visualization approaches that can augment and propel their research endeavors. Example research projects that have benefited from the VizInC laboratory follows:</p> <ul> <li>Advancing water sustainability capabilities through the integration, execution and interpretation of water models using participatory reasoning processes. The VizInC lab provided the technology for enhanced visualization to support collaboration among colleagues and participating institutions. Collaborators included the El Paso Water Utilities, the U.S. Environmental Protection Agency, the International Boundary, and the Water Commission. &nbsp;</li> <li>The Smart Social Connector project, an interdisciplinary project across computer science, civil engineering, and psychology, addresses social isolation due to age-related barriers. The project defined informed strategies for seniors to learn and adopt technology and aligning resources with community needs. The lab's large touchscreens allowed city representatives to interact with the software prototypes for feedback and improvement prior to transfer of the prototypes to the city for dissemination and maintenance.</li> <li>The Imaging and Behavioral Neuroscience (IBN) project used the instrumentation in the VizInC lab to invoke novel ways to visualize and explore the 3-D volume renders generated using the IBN facility's state-of-the-art lightsheet and confocal microscopes. The 3-D renderings were projected on the visualization wall to facilitate identifying extremely fine anatomical details and structural patterns, which would have been difficult with smaller display screens. The collaboration between VizInC and the IBN laboratory is essential to develop novel methods to visualize spatial data and showcase both facilities' capabilities. Notably, the findings of this work have been showcased at scientific forums and the International Society for Neuroscience meeting.</li> <li>The CroV visualization project harnessed the power of the render node and 3D projector to produce a simulation of the Cafeteria roenbergensis virus (CroV), a massive marine virus composed of a protein shell containing 120 million atoms. The project team created an array of 3-D and stereoscopic images and animations to replicate the process of virus assembly. This was achieved by automating the loading and placement of a substantial number of virus capsid proteins, simulating their Brownian motion. &nbsp;</li> <li>The Clinical Applied Physiology team utilized a 3D projector, coupled with a high-performance node for MRI and DICOM file processing. This setup was employed to create a three-dimensional model of the carotid arteries. This modeling task was accomplished using the software 3D Slicer, and the resulting model was visualized in 3-D stereoscopy using Paraview. It's worth noting that the carotid arteries, responsible for supplying blood to the brain and often involved in vascular diseases, were the focal point of this research.</li> </ul><br> <p>  Last Modified: 01/31/2024<br> Modified by: Ann&nbsp;Q&nbsp;Gates</p></div> <div class="porSideCol" ><div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2024/2018999/2018999_10704663_1706688579042_Visualization_of_Rat_s_Brain_Stem--rgov-214x142.jpg" original="/por/images/Reports/POR/2024/2018999/2018999_10704663_1706688579042_Visualization_of_Rat_s_Brain_Stem--rgov-800width.jpg" title="Visualization rat's brain stem"><img src="/por/images/Reports/POR/2024/2018999/2018999_10704663_1706688579042_Visualization_of_Rat_s_Brain_Stem--rgov-66x44.jpg" alt="Visualization rat's brain stem"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Student researchers with Dr. Arshad Khan analyzing the visualization of a rat's brain stem.</div> <div class="imageCredit">UTEP</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Ann&nbsp;Q&nbsp;Gates <div class="imageTitle">Visualization rat's brain stem</div> </div> </li></ul> </div> </div></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The NSF Major Research Instrumentation (MRI) program provided funds to the University of Texas at El Paso (UTEP)to purchase high performance, fully immersive visualization instrumentation to advance interdisciplinary research and research training. The instrumentation is housed at the Visualization & Interactive Collaboration (VizInC) Laboratory located in UTEP's newInterdisciplinary Research Building.Data and knowledge visualization are critical for analysis, understanding, discovery, and decision making. In addition, visualization instrumentation is critical to advance convergent research endeavors that have been a focus at UTEP over the last decade. The VizInC Lab is a resource for researchers, faculty, and professional staff who require an ultra-high resolution display surface geared for scientific exploratory research and collaboration. The lab is composed of two spaces, the visualization lab, and the interactive collaboration lab. The visualization lab can display high-resolution scientific data models and supports exploration of large complex data sets. The 3D projection system is available for faculty and researchers who require virtual reality capabilities for immersive visualization. This system is connected to a high-end rendering workstation. Paraview, the open-source data visualization tool, supports manipulation of complex data workflows, including those with different data formats and supports stereoscopic rendering for 3D visualizations and motion tracking. The multi-touch system is available for researchers who require interactive touch capabilities to facilitate exploration, understanding, and discovery of scientific models and datasets.   Through training centered on how to use software and visualization instrumentation, students (undergraduate and graduate) build competencies that prepare them for a competitive workforce. Researchers and post-docs also receive guidance on visualization approaches that can augment and propel their research endeavors. Example research projects that have benefited from the VizInC laboratory follows:  Advancing water sustainability capabilities through the integration, execution and interpretation of water models using participatory reasoning processes. The VizInC lab provided the technology for enhanced visualization to support collaboration among colleagues and participating institutions. Collaborators included the El Paso Water Utilities, the U.S. Environmental Protection Agency, the International Boundary, and the Water Commission.  The Smart Social Connector project, an interdisciplinary project across computer science, civil engineering, and psychology, addresses social isolation due to age-related barriers. The project defined informed strategies for seniors to learn and adopt technology and aligning resources with community needs. The lab's large touchscreens allowed city representatives to interact with the software prototypes for feedback and improvement prior to transfer of the prototypes to the city for dissemination and maintenance. The Imaging and Behavioral Neuroscience (IBN) project used the instrumentation in the VizInC lab to invoke novel ways to visualize and explore the 3-D volume renders generated using the IBN facility's state-of-the-art lightsheet and confocal microscopes. The 3-D renderings were projected on the visualization wall to facilitate identifying extremely fine anatomical details and structural patterns, which would have been difficult with smaller display screens. The collaboration between VizInC and the IBN laboratory is essential to develop novel methods to visualize spatial data and showcase both facilities' capabilities. Notably, the findings of this work have been showcased at scientific forums and the International Society for Neuroscience meeting. The CroV visualization project harnessed the power of the render node and 3D projector to produce a simulation of the Cafeteria roenbergensis virus (CroV), a massive marine virus composed of a protein shell containing 120 million atoms. The project team created an array of 3-D and stereoscopic images and animations to replicate the process of virus assembly. This was achieved by automating the loading and placement of a substantial number of virus capsid proteins, simulating their Brownian motion.  The Clinical Applied Physiology team utilized a 3D projector, coupled with a high-performance node for MRI and DICOM file processing. This setup was employed to create a three-dimensional model of the carotid arteries. This modeling task was accomplished using the software 3D Slicer, and the resulting model was visualized in 3-D stereoscopy using Paraview. It's worth noting that the carotid arteries, responsible for supplying blood to the brain and often involved in vascular diseases, were the focal point of this research.      Last Modified: 01/31/2024       Submitted by: AnnQGates]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
