<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: PPoSS: Planning: Unifying Software and Hardware to Achieve Performant and Scalable Zero-cost Parallelism in the Heterogeneous Future]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>128343.00</AwardTotalIntnAmount>
<AwardAmount>144343</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Damian Dechev</SignBlockName>
<PO_EMAI>ddechev@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Exploiting parallelism is essential to making full use of computer systems, and thus is intrinsic to most applications.  Building parallel programs that can truly achieve the performance the hardware is capable of is extremely challenging even for experts.  It requires a firm grasp of concepts that range from the very highest level to the very lowest, and that range is rapidly expanding.  This project approaches this challenge along two lines, "theory down" and "architecture up".  The first strives to simplify parallel programming through languages and algorithms.  The second line strives to accelerate parallel programs through compilers, operating systems, and the hardware.  The project's novelty is to bridge these two lines, which are usually treated quite distinctly by the research community. The unified team of researchers is addressing a specific subproblem, scheduling, and then determining how to expand out from it.  The project's impact is in making it possible for ordinary programmers to program future parallel systems in a very high-level way, yet achieve the performance possible on the machine.&lt;br/&gt;&lt;br/&gt;The project studies an "intermediate representation out" approach to making high-level parallel abstractions implementable so that they can be used with zero cost.  A core idea is to expand the compiler's intermediate representation such that it can capture both high-level parallel concepts and low-level machine and operating system structures, thus allowing full stack optimization.  This planning project will flesh out this concept and set the stage for a larger scale effort in the future.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.]]></AbstractNarration>
<MinAmdLetterDate>08/19/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/08/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2028851</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Dinda</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter A Dinda</PI_FULL_NAME>
<EmailAddress><![CDATA[pdinda@northwestern.edu]]></EmailAddress>
<NSF_ID>000341788</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Simone</FirstName>
<LastName>Campanoni</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Simone Campanoni</PI_FULL_NAME>
<EmailAddress><![CDATA[simonec@eecs.northwestern.edu]]></EmailAddress>
<NSF_ID>000710339</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate>07/08/2022</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nikos</FirstName>
<LastName>Hardavellas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nikos Hardavellas</PI_FULL_NAME>
<EmailAddress><![CDATA[nikos@northwestern.edu]]></EmailAddress>
<NSF_ID>000538510</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>EVANSTON</CityName>
<ZipCode>602080001</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>633 CLARK ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL09</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>EXZVPWZBLUE8</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602080001</ZipCode>
<StreetAddress><![CDATA[2233 Tech Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>042Y</Code>
<Text>PPoSS-PP of Scalable Systems</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~128343</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><h2 id="docs-internal-guid-4ea8c061-7fff-52cf-1105-d39066de407a" style="line-height: 1.38; margin-top: 18pt; margin-bottom: 6pt;" dir="ltr"><span style="font-size: 16pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Project Outcomes Report</span></h2> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Parallel computing is indispensable to achieving the high computing performance necessary for science and engineering, as well as, more recently, machine learning/AI.&nbsp; Unfortunately achieving high performance and efficiency can be extremely challenging and typically requires specialists.&nbsp; This is only expected to get worse with the advent of heterogeneous architectures. The main purpose of this planning project was to begin to address this problem.&nbsp;&nbsp;</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">This project provided a framework for integrating teams from Northwestern, Illinois Institute of Technology, and Carnegie Mellon to develop a large-scale proposal to NSF&rsquo;s PPoSS program.&nbsp; The overall concept was to combine the &ldquo;theory down&rdquo; and &ldquo;architecture up&rdquo; approaches to parallelism that are exemplified by the teams, and to explore what it would mean to develop an &ldquo;IR-out&rdquo; approach, centered around a compilation framework.&nbsp; This &ldquo;IR-out&rdquo; (intermediate representation) approach would target future heterogeneous parallel machines and attempt to simultaneously democratize programming of such machines while still achieving expert-level performance.&nbsp;&nbsp;&nbsp;</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">In addition to providing the ability to plan together, including in several workshops, the project also supported the collaborative teams ability to start work on several technical challenges together. &nbsp; The most visible of these is in heartbeat scheduling, which is an approach to modulating the amount of available parallelism in a program, one that has strong theoretical bounds.&nbsp; &nbsp; In the joint work, the team developed (a) two different compilation technologies (one based on assembly-level transforms, the other based on IR-level transforms) to enable heartbeat scheduling with minimal programmer effort, and (b) special kernel support (both a custom kernel, and a Linux kernel module) to provide the necessary runtime heartbeat signals effectively.&nbsp;&nbsp;</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Significant training opportunities resulted from the project.&nbsp; 7 Ph.D. students (4 NU, 2 IIT, 1 CMU), 1 MS student (IIT), 4 REU students (2 NU, 2 IIT),&nbsp; and 1 other undergraduate (IIT) were involved in the project. &nbsp; Several of the MS students and undergraduates joined Ph.D. programs.&nbsp; &nbsp; The project&rsquo;s three workshops each included about 30 attendees, providing greater exposure for students at every site, but particularly for Northwestern, which hosted each one and thus could easily send a broad range of students at all levels.&nbsp; &nbsp; Northwestern&rsquo;s undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs. &nbsp; A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic.&nbsp; A Northwestern course on compiler analysis and transformation was created, and Northwestern&rsquo;s compiler sequence was&nbsp; also considerably enhanced.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">&nbsp;&nbsp;</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial,sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The results of this project were very promising, including multiple joint publications and software, much of which is publicly available. &nbsp; The collaborative team was also successful in having the planned-for large-scale project supported by the NSF (with an additional element funded by DOE), and the resulting Constellation Project is now highly active.&nbsp; </span></p><br> <p>  Last Modified: 11/26/2023<br> Modified by: Peter&nbsp;A&nbsp;Dinda</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Project Outcomes Report   Parallel computing is indispensable to achieving the high computing performance necessary for science and engineering, as well as, more recently, machine learning/AI. Unfortunately achieving high performance and efficiency can be extremely challenging and typically requires specialists. This is only expected to get worse with the advent of heterogeneous architectures. The main purpose of this planning project was to begin to address this problem.      This project provided a framework for integrating teams from Northwestern, Illinois Institute of Technology, and Carnegie Mellon to develop a large-scale proposal to NSFs PPoSS program. The overall concept was to combine the theory down and architecture up approaches to parallelism that are exemplified by the teams, and to explore what it would mean to develop an IR-out approach, centered around a compilation framework. This IR-out (intermediate representation) approach would target future heterogeneous parallel machines and attempt to simultaneously democratize programming of such machines while still achieving expert-level performance.      In addition to providing the ability to plan together, including in several workshops, the project also supported the collaborative teams ability to start work on several technical challenges together.  The most visible of these is in heartbeat scheduling, which is an approach to modulating the amount of available parallelism in a program, one that has strong theoretical bounds.  In the joint work, the team developed (a) two different compilation technologies (one based on assembly-level transforms, the other based on IR-level transforms) to enable heartbeat scheduling with minimal programmer effort, and (b) special kernel support (both a custom kernel, and a Linux kernel module) to provide the necessary runtime heartbeat signals effectively.      Significant training opportunities resulted from the project. 7 Ph.D. students (4 NU, 2 IIT, 1 CMU), 1 MS student (IIT), 4 REU students (2 NU, 2 IIT), and 1 other undergraduate (IIT) were involved in the project.  Several of the MS students and undergraduates joined Ph.D. programs.  The projects three workshops each included about 30 attendees, providing greater exposure for students at every site, but particularly for Northwestern, which hosted each one and thus could easily send a broad range of students at all levels.  Northwesterns undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs.  A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic. A Northwestern course on compiler analysis and transformation was created, and Northwesterns compiler sequence was also considerably enhanced.      The results of this project were very promising, including multiple joint publications and software, much of which is publicly available.  The collaborative team was also successful in having the planned-for large-scale project supported by the NSF (with an additional element funded by DOE), and the resulting Constellation Project is now highly active.      Last Modified: 11/26/2023       Submitted by: PeterADinda]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
